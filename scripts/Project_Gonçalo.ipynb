{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gmgr1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split the document\n",
    "loader = PyPDFLoader(\"data/raw/TA-9-2024-0138_EN.pdf\")\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=100)\n",
    "split_docs = text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gmgr1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 2. Generate and store the embeddings using FAISS\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# Prepare FAISS index\n",
    "embedding_dim = model.get_sentence_embedding_dimension()  # Get the embedding dimension\n",
    "index = faiss.IndexFlatL2(embedding_dim)  # L2 distance index for similarity search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings and add to the FAISS index\n",
    "embeddings = []\n",
    "for doc in split_docs:\n",
    "    embedding = model.encode(doc.page_content)\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "embeddings = np.array(embeddings).astype('float32')  # Convert to float32\n",
    "index.add(embeddings)  # Add embeddings to the FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create a Retriever\n",
    "def retrieve_documents(query, top_k=3):\n",
    "    # 1. Create the embedding for the query\n",
    "    query_embedding = model.encode(query).astype('float32')  # Prepare query embedding\n",
    "\n",
    "    # 2. Search for the top_k closest embeddings in the FAISS index\n",
    "    distances, indices = index.search(query_embedding.reshape(1, -1), top_k)\n",
    "\n",
    "    # 3. Format the results\n",
    "    results = []\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        if idx != -1:  # Verify if the index is valid\n",
    "            # Access the content of the Document object\n",
    "            results.append((split_docs[idx].page_content, distances[0][i]))\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gmgr1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "#4 - Load the question-answering pipeline\n",
    "qa_pipeline = pipeline('question-answering', model='distilbert-base-cased-distilled-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(context, question):\n",
    "    # Ajuste o prompt para ser claro e fácil de entender\n",
    "    input_text = f\"You are a helpful assistant. Answer the question based on the context below. Context: {context}\\nQuestion: {question}\\nAnswer:\"\n",
    "\n",
    "    # Passing the question and context to the QA pipeline\n",
    "    results = qa_pipeline(question=question, context=context)\n",
    "    \n",
    "    # A resposta estará no campo 'answer' e o score na chave 'score'\n",
    "    answer = results['answer']\n",
    "    score = results['score']  # Captura o score do modelo\n",
    "    return answer, score  # Retorna a resposta e o score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5- Define the RAG chain\n",
    "def retrieve_and_generate_answer(question):\n",
    "    # Step 1: Retrieve the relevant chunks\n",
    "    retrieved_docs = retrieve_documents(question)\n",
    "    \n",
    "    # Debugging: Check the structure of the retrieved documents\n",
    "    print(\"Retrieved Documents:\", retrieved_docs)  # Check what is returned\n",
    "\n",
    "    # Join the content of the documents into a single context\n",
    "    context = \" \".join([doc[0] for doc in retrieved_docs])  # Access the first element of each tuple (the content)\n",
    "\n",
    "    # Step 2: Generate the answer using the context and question\n",
    "    answer, score = generate_answer(context, question)  # Agora captura o score também\n",
    "\n",
    "    \n",
    "    return answer, score  # Retorna a resposta e o score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Documents: [('6. The Commission shall adopt implementing acts setting out the detailed arrangements \\nand the conditions for the evaluations, including the detailed arrangements for involving \\nindependent experts, and the procedure for the selection thereof. Those implementing \\nacts shall be adopted in accordance with the examination procedure referred to in \\nArticle 98(2).\\n7. Prior to requesting access to the general-purpose AI model concerned, the AI Office may', 0.8358497), ('carrying out their tasks and activities. They shall neither seek nor take instructions from \\nanyone when exercising their tasks under paragraph 3. Each expert shall draw up a \\ndeclaration of interests, which shall be made publicly available. The AI Office shall \\nestablish systems and procedures to actively manage and prevent potential conflicts of \\ninterest.\\n5. The implementing act referred to in paragraph 1 shall include provisions on the', 0.8473401), ('Intelligence Act)\\n(Text with EEA relevance)\\nTHE EUROPEAN PARLIAMENT AND THE COUNCIL OF THE EUROPEAN UNION,\\nHaving regard to the Treaty on the Functioning of the European Union, and in particular Articles 16 \\nand 114 thereof,\\nHaving regard to the proposal from the European Commission,\\nAfter transmission of the draft legislative act to the national parliaments,\\nHaving regard to the opinion of the European Economic and Social Committee1,\\nHaving regard to the opinion of the European Central Bank2,', 0.8681185)]\n",
      "Question: What is the main topic of the article Artificial Inteligence Act about?\n",
      "Answer: general-purpose AI model\n",
      "Score: 8.446082233604102e-08\n"
     ]
    }
   ],
   "source": [
    "# 6. Invoke the RAG chain with a sample question\n",
    "question = \"What is the main topic of the article Artificial Inteligence Act about?\"\n",
    "answer, score = retrieve_and_generate_answer(question)\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)\n",
    "print(\"Score:\", score)  # Print the scores for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Documents: [('purposes of the effective enforcement of this Regulation:\\n(a) any reference to an economic operator under Regulation (EU) 2019/1020 shall be \\nunderstood as including all operators identified in Article 2(1) of this Regulation;\\n(b) any reference to a product under Regulation (EU) 2019/1020 shall be understood as \\nincluding all AI systems falling within the scope of this Regulation.', 0.7531761), ('(b) the effective implementation of this Regulation, in particular for the purposes of \\ninspections, investigations or audits; ▌\\n(c) public and national security interests;\\n(d) the conduct of criminal or administrative proceedings;\\n(e) information classified pursuant to Union or national law.\\n2. The authorities involved in the application of this Regulation pursuant to paragraph 1 \\nshall request only data that is strictly necessary for the assessment of the risk posed by', 0.78608364), ('Whereas:\\n(1) The purpose of this Regulation is to improve the functioning of the internal market by \\nlaying down a uniform legal framework in particular for the development, the placing on \\nthe market, the putting into service and the use of artificial intelligence systems (AI \\nsystems) in the Union, in accordance with Union values, to promote the uptake of human \\ncentric and trustworthy artificial intelligence (AI) while ensuring a high level of', 0.83831775)]\n",
      "Question: What is the purpose of this Regulation?\n",
      "Answer: to improve the functioning of the internal market\n",
      "Score: 0.4547649919986725\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the purpose of this Regulation?\"\n",
    "answer, score = retrieve_and_generate_answer(question)\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)\n",
    "print(\"Score:\", score)  # Print the scores for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Documents: [('Providers and deployers of AI systems shall take measures to ensure, to their best extent, a \\nsufficient level of AI literacy of their staff and other persons dealing with the operation and use \\nof AI systems on their behalf, taking into account their technical knowledge, experience, \\neducation and training and the context the AI systems are to be used in, and considering the \\npersons or groups of persons on whom the AI systems are to be used.', 1.0787231), ('including by requesting documentation and information, by conducting evaluations, as \\nwell as by requesting measures from providers of general-purpose AI models. When \\nconducting evaluations, in order to make use of independent expertise, the AI Office \\nshould be able to involve independent experts to carry out the evaluations on its behalf. \\nCompliance with the obligations should be enforceable, inter alia, through requests to', 1.0811049), ('(20) In order to obtain the greatest benefits from AI systems while protecting fundamental \\nrights, health and safety and to enable democratic control, AI literacy should equip \\nproviders, deployers and affected persons with the necessary notions to make informed \\ndecisions regarding AI systems. Those notions may vary with regard to the relevant \\ncontext and can include understanding the correct application of technical elements', 1.109306)]\n",
      "Question: What do I, as a Customer, need to know about Artifical Intelligence?\n",
      "Answer: their technical knowledge, experience, \n",
      "education and training\n",
      "Score: 0.12693306803703308\n"
     ]
    }
   ],
   "source": [
    "question = \"What do I, as a Customer, need to know about Artifical Intelligence?\"\n",
    "answer, score = retrieve_and_generate_answer(question)\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)\n",
    "print(\"Score:\", score)  # Print the scores for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
